#!/usr/bin/env python3
"""
VibeKit - complexity_analyzer.py

ä»£ç å¤æ‚åº¦åˆ†æå™¨ - æ£€æµ‹é«˜å¤æ‚åº¦å‡½æ•°å’Œé‡å¤ä»£ç 

åŠŸèƒ½ï¼š
- åœˆå¤æ‚åº¦åˆ†æï¼ˆCyclomatic Complexityï¼‰
- è®¤çŸ¥å¤æ‚åº¦åˆ†æï¼ˆCognitive Complexityï¼‰
- å‡½æ•°é•¿åº¦åˆ†æ
- é‡å¤ä»£ç æ£€æµ‹

ä½¿ç”¨ï¼š
    analyzer = ComplexityAnalyzer(project_path, modules)
    results = analyzer.analyze()
"""

import ast
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Set
from collections import defaultdict


class ComplexityAnalyzer:
    """ä»£ç å¤æ‚åº¦åˆ†æå™¨"""

    def __init__(self, project_path: Path, modules: List[Dict]):
        self.project_path = project_path
        self.modules = modules
        self.high_complexity_functions = []
        self.long_functions = []
        self.duplicates = []

    def analyze(self) -> Dict:
        """åˆ†æä»£ç å¤æ‚åº¦"""
        print("ğŸ“ åˆ†æä»£ç å¤æ‚åº¦...")

        all_functions = []

        # éå†æ‰€æœ‰æ¨¡å—
        for module in self.modules:
            module_path = self.project_path / module['path']
            functions = self._analyze_module(module_path, module['name'])
            all_functions.extend(functions)

        # 1. æ‰¾å‡ºé«˜å¤æ‚åº¦å‡½æ•°
        self.high_complexity_functions = [
            f for f in all_functions if f['complexity'] > 10
        ]

        # 2. æ‰¾å‡ºé•¿å‡½æ•°
        self.long_functions = [
            f for f in all_functions if f['lines'] > 50
        ]

        # 3. æ£€æµ‹é‡å¤ä»£ç 
        self.duplicates = self._detect_duplicates(all_functions)

        # ç»Ÿè®¡
        total_functions = len(all_functions)
        avg_complexity = sum(f['complexity'] for f in all_functions) / total_functions if total_functions > 0 else 0
        avg_length = sum(f['lines'] for f in all_functions) / total_functions if total_functions > 0 else 0

        print(f"   åˆ†æäº† {total_functions} ä¸ªå‡½æ•°")
        print(f"   å¹³å‡å¤æ‚åº¦ï¼š{avg_complexity:.1f}")
        print(f"   å¹³å‡é•¿åº¦ï¼š{avg_length:.1f} è¡Œ")

        if self.high_complexity_functions:
            print(f"   âš ï¸  å‘ç° {len(self.high_complexity_functions)} ä¸ªé«˜å¤æ‚åº¦å‡½æ•°")
        else:
            print(f"   âœ… æœªå‘ç°é«˜å¤æ‚åº¦å‡½æ•°")

        if self.long_functions:
            print(f"   âš ï¸  å‘ç° {len(self.long_functions)} ä¸ªé•¿å‡½æ•°")
        else:
            print(f"   âœ… æœªå‘ç°é•¿å‡½æ•°")

        if self.duplicates:
            duplicate_rate = len(self.duplicates) / total_functions * 100 if total_functions > 0 else 0
            print(f"   âš ï¸  ä»£ç é‡å¤ç‡ï¼š{duplicate_rate:.1f}%")
        else:
            print(f"   âœ… æœªå‘ç°é‡å¤ä»£ç ")

        return {
            'total_functions': total_functions,
            'avg_complexity': round(avg_complexity, 1),
            'avg_length': round(avg_length, 1),
            'high_complexity_functions': self.high_complexity_functions,
            'long_functions': self.long_functions,
            'duplicates': self.duplicates
        }

    def _analyze_module(self, module_path: Path, module_name: str) -> List[Dict]:
        """åˆ†ææ¨¡å—å†…çš„æ‰€æœ‰å‡½æ•°"""
        functions = []

        for py_file in module_path.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # è§£æ AST
                tree = ast.parse(content)

                # åˆ†æå‡½æ•°
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        func_info = self._analyze_function(node, py_file, module_name, content)
                        if func_info:
                            functions.append(func_info)

            except Exception as e:
                # è·³è¿‡æ— æ³•è§£æçš„æ–‡ä»¶
                continue

        return functions

    def _analyze_function(self, node: ast.FunctionDef, file_path: Path, module_name: str, content: str) -> Dict:
        """åˆ†æå•ä¸ªå‡½æ•°"""
        # è®¡ç®—åœˆå¤æ‚åº¦
        complexity = self._calculate_complexity(node)

        # è®¡ç®—å‡½æ•°é•¿åº¦
        lines = self._calculate_lines(node)

        # è·å–å‡½æ•°æºç 
        source_lines = content.split('\n')
        func_source = '\n'.join(source_lines[node.lineno - 1:node.end_lineno])

        # è®¡ç®—å‡½æ•°ç­¾åå“ˆå¸Œï¼ˆç”¨äºé‡å¤æ£€æµ‹ï¼‰
        func_hash = self._calculate_hash(func_source)

        return {
            'name': node.name,
            'module': module_name,
            'file': str(file_path.relative_to(self.project_path)),
            'line': node.lineno,
            'complexity': complexity,
            'lines': lines,
            'source': func_source,
            'hash': func_hash
        }

    def _calculate_complexity(self, node: ast.FunctionDef) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰

        åœˆå¤æ‚åº¦ = å†³ç­–ç‚¹æ•°é‡ + 1
        å†³ç­–ç‚¹ï¼šif, elif, for, while, except, and, or, assert
        """
        complexity = 1  # åŸºç¡€å¤æ‚åº¦

        for child in ast.walk(node):
            # if è¯­å¥
            if isinstance(child, ast.If):
                complexity += 1
            # for/while å¾ªç¯
            elif isinstance(child, (ast.For, ast.While)):
                complexity += 1
            # except è¯­å¥
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            # å¸ƒå°”è¿ç®—ç¬¦ (and, or)
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
            # åˆ—è¡¨/å­—å…¸/é›†åˆæ¨å¯¼å¼
            elif isinstance(child, (ast.ListComp, ast.DictComp, ast.SetComp, ast.GeneratorExp)):
                complexity += 1
            # assert è¯­å¥
            elif isinstance(child, ast.Assert):
                complexity += 1

        return complexity

    def _calculate_lines(self, node: ast.FunctionDef) -> int:
        """è®¡ç®—å‡½æ•°è¡Œæ•°"""
        if node.end_lineno and node.lineno:
            return node.end_lineno - node.lineno + 1
        return 0

    def _calculate_hash(self, source: str) -> str:
        """è®¡ç®—æºç å“ˆå¸Œï¼ˆå½’ä¸€åŒ–åï¼‰"""
        # ç®€å•å½’ä¸€åŒ–ï¼šç§»é™¤ç©ºç™½ç¬¦ã€æ³¨é‡Š
        normalized = ''.join(source.split())
        return hashlib.md5(normalized.encode()).hexdigest()[:8]

    def _detect_duplicates(self, functions: List[Dict]) -> List[Dict]:
        """æ£€æµ‹é‡å¤ä»£ç 

        ç®€å•ç­–ç•¥ï¼š
        1. åŸºäºå“ˆå¸Œå€¼åˆ†ç»„
        2. ç›¸åŒå“ˆå¸Œå€¼çš„å‡½æ•°è§†ä¸ºé‡å¤
        3. åªä¿ç•™å‡ºç° >= 2 æ¬¡çš„
        """
        duplicates = []

        # æŒ‰å“ˆå¸Œå€¼åˆ†ç»„
        hash_groups = defaultdict(list)
        for func in functions:
            hash_groups[func['hash']].append(func)

        # æ‰¾å‡ºé‡å¤çš„ç»„
        for func_hash, group in hash_groups.items():
            if len(group) >= 2:
                # æ£€æŸ¥æ˜¯å¦çœŸçš„é‡å¤ï¼ˆä¸åªæ˜¯å“ˆå¸Œå†²çªï¼‰
                # ç®€å•æ£€æŸ¥ï¼šè¡Œæ•°å’Œå¤æ‚åº¦ç›¸åŒ
                if self._is_duplicate_group(group):
                    duplicates.append({
                        'count': len(group),
                        'functions': [
                            {
                                'name': f['name'],
                                'module': f['module'],
                                'file': f['file'],
                                'line': f['line']
                            }
                            for f in group
                        ],
                        'lines': group[0]['lines'],
                        'complexity': group[0]['complexity']
                    })

        return duplicates

    def _is_duplicate_group(self, group: List[Dict]) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯çœŸæ­£çš„é‡å¤ç»„"""
        if len(group) < 2:
            return False

        # æ£€æŸ¥è¡Œæ•°å’Œå¤æ‚åº¦æ˜¯å¦ç›¸åŒ
        first = group[0]
        for func in group[1:]:
            if func['lines'] != first['lines'] or func['complexity'] != first['complexity']:
                return False

        return True


class CodeMetrics:
    """ä»£ç åº¦é‡ç»Ÿè®¡"""

    @staticmethod
    def calculate_file_metrics(file_path: Path) -> Dict:
        """è®¡ç®—æ–‡ä»¶çº§åˆ«çš„åº¦é‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.split('\n')
            total_lines = len(lines)

            # ç©ºè¡Œ
            blank_lines = sum(1 for line in lines if not line.strip())

            # æ³¨é‡Šè¡Œï¼ˆç®€åŒ–ï¼šä»¥ # å¼€å¤´ï¼‰
            comment_lines = sum(1 for line in lines if line.strip().startswith('#'))

            # ä»£ç è¡Œ
            code_lines = total_lines - blank_lines - comment_lines

            return {
                'total_lines': total_lines,
                'code_lines': code_lines,
                'blank_lines': blank_lines,
                'comment_lines': comment_lines,
                'comment_ratio': round(comment_lines / code_lines * 100, 1) if code_lines > 0 else 0
            }

        except Exception as e:
            return {
                'total_lines': 0,
                'code_lines': 0,
                'blank_lines': 0,
                'comment_lines': 0,
                'comment_ratio': 0
            }

    @staticmethod
    def categorize_complexity(complexity: int) -> Tuple[str, str]:
        """åˆ†ç±»å¤æ‚åº¦"""
        if complexity <= 5:
            return "ç®€å•", "âœ…"
        elif complexity <= 10:
            return "ä¸­ç­‰", "âš ï¸"
        elif complexity <= 20:
            return "å¤æ‚", "âš ï¸"
        else:
            return "æå¤æ‚", "âŒ"

    @staticmethod
    def categorize_length(lines: int) -> Tuple[str, str]:
        """åˆ†ç±»å‡½æ•°é•¿åº¦"""
        if lines <= 20:
            return "çŸ­", "âœ…"
        elif lines <= 50:
            return "é€‚ä¸­", "âœ…"
        elif lines <= 100:
            return "è¾ƒé•¿", "âš ï¸"
        else:
            return "è¿‡é•¿", "âŒ"


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ç”¨æ³•ï¼špython complexity_analyzer.py <é¡¹ç›®è·¯å¾„>")
        sys.exit(1)

    project_path = Path(sys.argv[1])

    # ç®€å•æµ‹è¯•
    modules = [
        {"name": "test", "path": ".", "type": "directory"}
    ]

    analyzer = ComplexityAnalyzer(project_path, modules)
    results = analyzer.analyze()

    print(f"\nåˆ†æç»“æœï¼š")
    print(f"  æ€»å‡½æ•°æ•°ï¼š{results['total_functions']}")
    print(f"  å¹³å‡å¤æ‚åº¦ï¼š{results['avg_complexity']}")
    print(f"  å¹³å‡é•¿åº¦ï¼š{results['avg_length']} è¡Œ")
    print(f"  é«˜å¤æ‚åº¦å‡½æ•°ï¼š{len(results['high_complexity_functions'])} ä¸ª")
    print(f"  é•¿å‡½æ•°ï¼š{len(results['long_functions'])} ä¸ª")
    print(f"  é‡å¤ä»£ç ç»„ï¼š{len(results['duplicates'])} ç»„")
